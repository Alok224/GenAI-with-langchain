{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c0f5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv--research\n",
    "# tools-creation\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8133118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28185820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "# used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "# to run this wrraper\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9076f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "# used the inbuilt tool of arxiv\n",
    "arxiv_wrapper_api = ArxivAPIWrapper(top_k_results = 1, doc_content_chars_max = 250)\n",
    "arxiv = ArxivQueryRun(api_wrapper = arxiv_wrapper_api)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90252ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I want to combine both of these tools\n",
    "tools = [wiki,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c4c9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to create tools [rag tools]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a80d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the webpage\n",
    "loader = WebBaseLoader(\"https://www.langchain.com/langsmith\")\n",
    "docs = loader.load()\n",
    "# split the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "# create the vector store\n",
    "vectorstore = FAISS.from_documents(split_docs,embedding = HuggingFaceEmbeddings())\n",
    "# Now use the retriever to retrieve the relavant documents\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "744e66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith-search\n"
     ]
    }
   ],
   "source": [
    "# To create the tool, convert the retriever into a tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever = retriever, name = \"Langsmith-search\", description = \"useful for when you want to find information about langsmith\")\n",
    "print(retriever_tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "482c2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bde41067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the tools and agents with LLM model\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1306f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# prompt template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f25edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableAssign(mapper={\n",
      "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
      "}) middle=[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]), RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000014A289068D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000014A2A0D0510>, model_name='Llama3-8b-8192'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'Langsmith-search', 'description': 'useful for when you want to find information about langsmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})] last=OpenAIToolsAgentOutputParser()\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm = llm, tools= tools, prompt=prompt)\n",
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcc57c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
      "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
      "})\n",
      "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
      "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000014A289068D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000014A2A0D0510>, model_name='Llama3-8b-8192'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'Langsmith-search', 'description': 'useful for when you want to find information about langsmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
      "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True) tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\HP\\\\Desktop\\\\Langchain\\\\langenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='Langsmith-search', description='useful for when you want to find information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000014A72659A80>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000014A7128EF10>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000014A72659BC0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000014A7128EF10>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]\n"
     ]
    }
   ],
   "source": [
    "# Agent Execution\n",
    "from langchain.agents import AgentExecutor\n",
    "agentexecutor = AgentExecutor(agent = agent,tools = tools, verbose = True)\n",
    "print(agentexecutor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2daba48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Langsmith-search` with `{'query': 'langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mYes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\n",
      "\n",
      "LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance — including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I can’t have data leave my environment. Can I self-host LangSmith?\n",
      "\n",
      "Yes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?\n",
      "\n",
      "feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI agents, from design to production.Get the eBookLangSmith FAQsMy application isn’t written in Python or TypeScript. Will LangSmith be helpful?\n",
      "\n",
      "For Cloud SaaS, traces are stored in GCP us-central-1 or GCP europe-west4, depending on your plan. Learn more.Will LangSmith add latency to my application?\n",
      "\n",
      "No, LangSmith does not add any latency to your application. In the LangSmith SDK, there’s a callback handler that sends traces to a LangSmith trace collector which runs as an async, distributed process. Additionally, if LangSmith experiences an incident, your application performance will not be disrupted.Will you train on the data that I send LangSmith?\n",
      "\n",
      "We will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?\n",
      "\n",
      "LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Products\n",
      "\n",
      "FrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\n",
      "\n",
      "GuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\n",
      "\n",
      "PythonLangGraphLangSmithLangChainJavaScriptLangGraphLangSmithLangChainCompany\n",
      "\n",
      "AboutCareersPricingGet a demoSign upShip agents with confidence.LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance — whether building with LangChain or not.Get a demoSign up for free\n",
      "\n",
      "LangSmith is now available on AWS Marketplace.Get started\n",
      "\n",
      "\n",
      "Helping top teams ship reliable agents.Find failures fast with agent observability.Quickly debug and understand non-deterministic LLM app behavior with tracing. See what your agent is doing step by step —then fix issues to improve latency and response quality.Get started tracing your app\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that LangSmith is a platform designed for observability and evaluation of AI applications, particularly those built using LangChain. It provides features such as tracing, running evals, and prompt engineering, allowing developers to debug, test, and monitor their AI app performance. LangSmith also allows users to self-host the platform on their own Kubernetes cluster, ensuring that data remains within their environment.\n",
      "\n",
      "It's also clear that LangSmith is designed to be flexible and works with various programming languages, including Python and TypeScript. Additionally, LangSmith does not add any latency to the application and does not train on user data, giving users full control over their data.\n",
      "\n",
      "Overall, LangSmith seems to be a powerful tool for developers building AI applications, providing them with the necessary insights to improve their app's performance and reliability.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': \"It seems that LangSmith is a platform designed for observability and evaluation of AI applications, particularly those built using LangChain. It provides features such as tracing, running evals, and prompt engineering, allowing developers to debug, test, and monitor their AI app performance. LangSmith also allows users to self-host the platform on their own Kubernetes cluster, ensuring that data remains within their environment.\\n\\nIt's also clear that LangSmith is designed to be flexible and works with various programming languages, including Python and TypeScript. Additionally, LangSmith does not add any latency to the application and does not train on user data, giving users full control over their data.\\n\\nOverall, LangSmith seems to be a powerful tool for developers building AI applications, providing them with the necessary insights to improve their app's performance and reliability.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentexecutor.invoke({\"input\" : \"Tell me about langsmith\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad7a433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\n",
      "\n",
      "LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance — including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I can’t have data leave my environment. Can I self-host LangSmith?\n",
      "\n",
      "Yes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?\n",
      "\n",
      "For Cloud SaaS, traces are stored in GCP us-central-1 or GCP europe-west4, depending on your plan. Learn more.Will LangSmith add latency to my application?\n",
      "\n",
      "No, LangSmith does not add any latency to your application. In the LangSmith SDK, there’s a callback handler that sends traces to a LangSmith trace collector which runs as an async, distributed process. Additionally, if LangSmith experiences an incident, your application performance will not be disrupted.Will you train on the data that I send LangSmith?\n",
      "\n",
      "We will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?\n",
      "\n",
      "feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI agents, from design to production.Get the eBookLangSmith FAQsMy application isn’t written in Python or TypeScript. Will LangSmith be helpful?\n",
      "\n",
      "We will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?\n",
      "\n",
      "See our pricing page for more information, and find a plan that works for you.Ready to start shipping  reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangSmithLangGraphResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogExpertsPython DocsLangGraph LangSmithLangChainJS DocsLangGraphLangSmithLangChainCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service\n"
     ]
    }
   ],
   "source": [
    "print(retriever_tool.run(\"Tell me about langsmith\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972245f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
